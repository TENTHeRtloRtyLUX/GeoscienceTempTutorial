{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0a881fd",
   "metadata": {},
   "source": [
    "## Simple example - Temperature Only Analysis\n",
    "This notebook shows how to train model for temperature data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e54843ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy\n",
    "import torch\n",
    "\n",
    "sys.path.append('../src/')\n",
    "from DatasetUS import *\n",
    "# from TrainDiffusion import *  # COMMENTED OUT - Temporarily using U-Net for testing\n",
    "# import Network  # Import Network module for EDMPrecond\n",
    "from TrainUnet import *  # UNCOMMENTED - Using U-Net for testing weekly data\n",
    "import Network  # Import Network module for UNet\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ea9cf8",
   "metadata": {},
   "source": [
    "This example can be run on a laptop but won't train the network very well. We will train with just a small subset of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84259f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select years to train and validate\n",
    "train_year_start = 1953\n",
    "train_year_end = 1955\n",
    "\n",
    "valid_year_start = 1956\n",
    "valid_year_end = 1957"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046b82d1",
   "metadata": {},
   "source": [
    "Set up training hyperparameters. We will only run for 10 epochs and we will use the cpu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57f67c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening files\n",
      "All files accessed. Creating tensors\n",
      "torch.Size([1])\n",
      "tensor([259.5524]) tensor([310.5276])\n",
      "Opening constant variables file (e.g. land-sea mask, topography)\n",
      "Normalize z\n",
      "Mean:4599.646526826994, Std6220.799692544967\n",
      "Dataset initialized.\n",
      "Opening files\n",
      "All files accessed. Creating tensors\n",
      "torch.Size([1])\n",
      "tensor([259.5524]) tensor([310.5276])\n",
      "Opening constant variables file (e.g. land-sea mask, topography)\n",
      "Normalize z\n",
      "Mean:4599.646526826994, Std6220.799692544967\n",
      "Dataset initialized.\n"
     ]
    }
   ],
   "source": [
    "## Select hyperparameters of training\n",
    "batch_size = 4  # Reduced from 16 to fit RTX 4050 (6GB VRAM)\n",
    "learning_rate = 1e-4\n",
    "accum = 8\n",
    "\n",
    "# Run training for small number of epochs \n",
    "num_epochs = 2        \n",
    "\n",
    "# Define device\n",
    "torch.cuda.set_device(0)  # Use GPU 1 as default\n",
    "device = 'cuda'  # Will use GPU 1\n",
    "# if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# define the ml model - TEMPORARILY USING U-NET FOR TESTING WEEKLY DATA\n",
    "unet_model = UNet((256, 128), 3, 1, label_dim=2, use_diffuse=False)  # UNCOMMENTED - U-Net for testing\n",
    "unet_model.to(device)\n",
    "# diffusion_model = Network.EDMPrecond((256, 128), 3, 1, label_dim=2)  # COMMENTED OUT - Temporarily using U-Net\n",
    "\n",
    "# define the datasets\n",
    "datadir = \"../data/\"\n",
    "dataset_train = UpscaleDataset(datadir, year_start=train_year_start, year_end=train_year_end,\n",
    "                               constant_variables=[\"lsm\", \"z\"])\n",
    "\n",
    "dataset_test = UpscaleDataset(datadir, year_start=valid_year_start, year_end=valid_year_end,\n",
    "                              constant_variables=[\"lsm\", \"z\"])\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(\n",
    "    dataset_train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "dataloader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a0255e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180 90\n",
      "Input shape: torch.Size([4, 3, 128, 256])\n",
      "Target shape: torch.Size([4, 1, 128, 256])\n",
      "Expected input channels: 3 (1 temp + 2 constants)\n",
      "Actual input channels: 3\n",
      "Model expects: 3 channels\n",
      "\\nDataset configuration:\n",
      "- Temperature variables: ['temp']\n",
      "- Number of temperature variables: 1\n",
      "- Constant variables: ['lsm', 'z']\n",
      "- Expected total channels: 3 (temp + constants)\n",
      "\\nWeekly Data Subsampling:\n",
      "- Original data: Daily (365 days/year)\n",
      "- Weekly data: Every 7th day (52 days/year)\n",
      "- Data reduction: 86% (365 → 52 days)\n",
      "- Expected training speed: 7x faster\n",
      "- Training samples (weekly): 156\n",
      "- Validation samples (weekly): 104\n"
     ]
    }
   ],
   "source": [
    "print(len(dataloader_train), len(dataloader_test))\n",
    "\n",
    "# Debug: Check the actual data shapes\n",
    "batch = next(iter(dataloader_train))\n",
    "print(\"Input shape:\", batch[\"inputs\"].shape)\n",
    "print(\"Target shape:\", batch[\"targets\"].shape)\n",
    "print(\"Expected input channels: 3 (1 temp + 2 constants)\")\n",
    "print(\"Actual input channels:\", batch[\"inputs\"].shape[1])\n",
    "print(\"Model expects:\", 3, \"channels\")\n",
    "\n",
    "# Check what channels we actually have\n",
    "print(\"\\\\nDataset configuration:\")\n",
    "print(\"- Temperature variables:\", dataset_train.varnames)\n",
    "print(\"- Number of temperature variables:\", dataset_train.n_var)\n",
    "print(\"- Constant variables:\", [\"lsm\", \"z\"])\n",
    "print(\"- Expected total channels:\", dataset_train.n_var + 2, \"(temp + constants)\")\n",
    "\n",
    "# WEEKLY DATA SUBSAMPLING INFO\n",
    "print(\"\\\\nWeekly Data Subsampling:\")\n",
    "print(\"- Original data: Daily (365 days/year)\")\n",
    "print(\"- Weekly data: Every 7th day (52 days/year)\")\n",
    "print(\"- Data reduction: 86% (365 → 52 days)\")\n",
    "print(\"- Expected training speed: 7x faster\")\n",
    "print(\"- Training samples (weekly):\", (train_year_end - train_year_start + 1) * 52)\n",
    "print(\"- Validation samples (weekly):\", (valid_year_end - valid_year_start + 1) * 52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23a98be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory: 6.4 GB\n",
      "GPU Memory Allocated: 3.66 GB\n",
      "GPU Memory Cached: 4.16 GB\n"
     ]
    }
   ],
   "source": [
    "# Clear GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Check GPU memory\n",
    "print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "print(f\"GPU Memory Allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
    "print(f\"GPU Memory Cached: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")\n",
    "\n",
    "scaler = torch.amp.GradScaler('cuda')  # Updated for newer PyTorch\n",
    "\n",
    "# define the optimiser - TEMPORARILY USING U-NET\n",
    "optimiser = torch.optim.AdamW(unet_model.parameters(), lr=learning_rate)\n",
    "# optimiser = torch.optim.AdamW(diffusion_model.parameters(), lr=learning_rate)  # COMMENTED OUT - Using U-Net\n",
    "\n",
    "# Define the tensorboard writer\n",
    "writer = SummaryWriter(\"./runs_unet\")  # UNCOMMENTED - Using U-Net for testing\n",
    "# writer = SummaryWriter(\"./runs_diffusion\")  # COMMENTED OUT - Using U-Net\n",
    "\n",
    "# define loss function - MSE Loss for U-Net\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "# loss_fn = EDMLoss()  # COMMENTED OUT - Using U-Net\n",
    "\n",
    "# train the model\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2c8cf9",
   "metadata": {},
   "source": [
    "Start the training loop using U-Net framework with weekly data. The plots generated will show the coarse res, the predicted, and the truth for a few samples and for different variables. At the start of training the first two columns (coarse res and predicted) look similar. Towards the end of the training, the last two columns (predicted and truth) should look similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abfebf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:   1%|          | 1/180 [00:08<24:21,  8.17s/it]c:\\Users\\khosl\\OneDrive\\Documents\\ClimateDiffuse-main\\examples\\../src\\TrainUnet.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Train :: Epoch: 0:  47%|████▋     | 84/180 [26:53<1:19:06, 49.44s/it, Loss: 0.7798]"
     ]
    }
   ],
   "source": [
    "for step in range(num_epochs):\n",
    "    # Clear GPU memory before each epoch\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Use U-Net training step for weekly data testing\n",
    "    epoch_loss = train_step(\n",
    "        unet_model, loss_fn, dataloader_train, optimiser,\n",
    "        scaler, step, accum, writer, device=device)\n",
    "    losses.append(epoch_loss)\n",
    "\n",
    "    # Use U-Net sampling for weekly data testing\n",
    "    (fig, ax), (base_error, pred_error) = sample_model(\n",
    "        unet_model, dataloader_test, device=device)\n",
    "    plt.show()\n",
    "\n",
    "    writer.add_scalar(\"Error/base\", base_error, step)\n",
    "    writer.add_scalar(\"Error/pred\", pred_error, step)\n",
    "    \n",
    "    # Clear memory after each epoch\n",
    "    torch.cuda.empty_cache()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
